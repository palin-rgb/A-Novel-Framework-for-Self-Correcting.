# A-Novel-Framework-for-Self-Correcting.
 This repository contains the prototype for a "Crisis-Driven Learning" artificial intelligence. Unlike traditional reinforcement learning, this agent does not require rewards. Instead, it learns by treating high prediction errors as logical "crises," which trigger non-monotonic belief revision to build a coherent and interpretable world model.
 ğŸ“ Project Structure

crisis-learning-ai/
â”œâ”€â”€ core/                       # Core AI architecture
â”‚   â”œâ”€â”€ belief_base.py          # Non-monotonic belief engine (Crisis Engine)
â”‚   â”œâ”€â”€ predictive_sensor.py    # Neural network predictor
â”‚   â””â”€â”€ agent.py                # Main agent class
â”œâ”€â”€ environments/               # Worlds for the agent
â”‚   â”œâ”€â”€ one_d_world.py          # Original 1D learning sandbox
â”‚   â””â”€â”€ maze_3d/                # 3D raycasting maze environment
â”‚       â”œâ”€â”€ raycaster.py        # First-person 3D perception
â”‚       â””â”€â”€ crisis_maze_3d.py   # Interactive 3D maze
â”œâ”€â”€ demos/                      # Ready-to-run demonstrations
â”‚   â”œâ”€â”€ run_1d_demo.py
â”‚   â””â”€â”€ run_3d_maze.py
â”œâ”€â”€ assets/                     # Screenshots, diagrams
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md                   (This file)
